{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages\n",
      "Packages Imported\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing packages\")\n",
    "from pycbc import distributions\n",
    "from pycbc.waveform import get_td_waveform, td_approximants\n",
    "from pycbc.detector import Detector\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gwpy\n",
    "import pylab\n",
    "from tqdm.notebook import tqdm\n",
    "from gwpy.timeseries import TimeSeries\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "print(\"Packages Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Binary Mass Distributions for BBH\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Generated Binary Mass Distributions for BBH\")\n",
    "# We can make pairs of distributions together, instead of apart.\n",
    "bbh_two_mass_distributions = distributions.Uniform(mass1=(10, 50),\n",
    "                                               mass2=(10, 50))\n",
    "\n",
    "bbh_two_mass_samples = bbh_two_mass_distributions.rvs(size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Binary Mass Distributions to generate BBH waveforms\n",
      "Generating BBH Waveforms, Noise and Merging them together and writing into disk, it may take few minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783d7d0e51d141d5a05c0fbdc7cf3a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycbc import frame\n",
    "#import random-\n",
    "#from numpy import random\n",
    "print(\"Using Binary Mass Distributions to generate BBH waveforms\")\n",
    "print(\"Generating BBH Waveforms, Noise and Merging them together and writing into disk, it may take few minutes...\")\n",
    "for i in tqdm(range(len(bbh_two_mass_samples))):\n",
    "    hp, hc = get_td_waveform(approximant=\"SEOBNRv2\",                                # what are hp and hc?\n",
    "                         mass1=bbh_two_mass_samples[i][0],\n",
    "                         mass2=bbh_two_mass_samples[i][1],\n",
    "                         delta_t=1.0/4096,\n",
    "                         f_lower=40)                                                # change to 40 Hz\n",
    "\n",
    "    noise = TimeSeries(np.random.normal(scale=.1, size=16384), sample_rate=4096)    # did not understand clearly    \n",
    "    noise= noise*1e-18\n",
    "    st = np.random.randint(0,2)\n",
    "    #st = round(st,0)\n",
    "    #hp.save(\"bbh_template_4k/bbh_4k_\"+str(i+1)+\".txt\")\n",
    "    #frame.write_frame(\"bbh_template_4k/bbh_4k_\"+str(i+1)+\".gwf\", , hp)\n",
    "    #pylab.plot(hp.sample_times, hp, label='H1')\n",
    "    #pylab.plot(noise)\n",
    "    signal = TimeSeries.from_pycbc(hp)\n",
    "    \n",
    "    signal.write(\"new_data_4s_reduced_noise_no_abs/bbh_signal/bbh_4k_\"+str(i)+\".txt\")\n",
    "    noise.write(\"new_data_4s_reduced_noise_no_abs/noise_templates/noise_4k_\"+str(i)+\".txt\")\n",
    "    #print(st)\n",
    "    \n",
    "    signal.t0 = st\n",
    "    data = noise.inject(signal)\n",
    "    #pylab.plot(data)\n",
    "    data.write(\"new_data_4s_reduced_noise_no_abs/merged_noise_signal/merged_noise_signal_\"+str(i)+\".txt\")\n",
    "\n",
    "#pylab.ylabel('Strain')\n",
    "#pylab.xlabel('Time (s)')\n",
    "#pylab.legend()\n",
    "#pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98107dad5e64f66904c9853f24f6392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MERGING NOISE + SIgnal Templates into single file\n",
    "\n",
    "\n",
    "#for i in tqdm(range(5)):\n",
    "path = \"new_data_4s_reduced_noise_no_abs/merged_noise_signal/\"\n",
    "files= os.listdir(path)\n",
    "f = open('new_data_4s_reduced_noise_no_abs/Final_Merged_Noise_Signal_Reduced_No_ABS.csv', 'w')\n",
    "cw = csv.writer(f)\n",
    "\n",
    "for i in tqdm(files):\n",
    "    df = pd.read_csv(path+i,sep = ' ', header=None)\n",
    "    c = df[:][1]\n",
    "    cw.writerow(c)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbea803527af4244be8501aac695b2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MERGING NOISE Templates into single file\n",
    "\n",
    "path_1 = \"new_data_4s_reduced_noise_no_abs/noise_templates/\"\n",
    "files_1= os.listdir(path_1)\n",
    "f1 = open('new_data_4s_reduced_noise_no_abs/Final_Merged_Noise_Reduced_No_Abs.csv', 'w')\n",
    "cw_1 = csv.writer(f1)\n",
    "\n",
    "for i in tqdm(files_1):\n",
    "    #print(files)\n",
    "    df = pd.read_csv(path_1+i,sep = ' ', header=None)\n",
    "    c = df[:][1]\n",
    "    cw_1.writerow(c)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7142d8c669194515ba73be0ae83acd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MERGING SIGNAL Templates into single file\n",
    "\n",
    "path_1 = \"new_data_4s_reduced_noise_no_abs/bbh_signal/\"\n",
    "files_1= os.listdir(path_1)\n",
    "f1 = open('new_data_4s_reduced_noise_no_abs/Final_Merged_bbh_Signal_Reduced_No_Abs.csv', 'w')\n",
    "cw_1 = csv.writer(f1)\n",
    "\n",
    "for i in tqdm(files_1):\n",
    "    #print(files)\n",
    "    df = pd.read_csv(path_1+i,sep = ' ', header=None)\n",
    "    c = df[:][1]\n",
    "    cw_1.writerow(c)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Binary Mass Distributions for BNS\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Binary Mass Distributions for BNS\")\n",
    "# We can make pairs of distributions together, instead of apart.\n",
    "bns_two_mass_distributions = distributions.Uniform(mass1=(1, 2),\n",
    "                                               mass2=(1, 2))\n",
    "\n",
    "bns_two_mass_samples = bns_two_mass_distributions.rvs(size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Binary Mass Distributions to generate BNS waveforms\n",
      "Generating BBH Waveforms, Noise and Merging them together and writing into disk, it may take few minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993eb1c1b62e41a29a29b5349a00ae3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycbc import frame\n",
    "#import random\n",
    "#from numpy import random\n",
    "print(\"Using Binary Mass Distributions to generate BNS waveforms\")\n",
    "print(\"Generating BBH Waveforms, Noise and Merging them together and writing into disk, it may take few minutes...\")\n",
    "for i in tqdm(range(len(bns_two_mass_samples))):\n",
    "    hp, hc = get_td_waveform(approximant=\"IMRPhenomPv2_NRTidal\", \n",
    "                         mass1=bns_two_mass_samples[i][0],\n",
    "                         mass2=bns_two_mass_samples[i][1],\n",
    "                         delta_t=1.0/4096,\n",
    "                         f_lower=40)            #change to 40   SEOBNRv2\n",
    "    \n",
    "    # noise = TimeSeries(np.random.normal(scale=.1, size=16384), sample_rate=4096)\n",
    "    # noise = noise*1e-18\n",
    "\n",
    "    noise = TimeSeries.read(\"new_data_4s_reduced_noise_no_abs/noise_templates/noise_4k_\"+str(i)+\".txt\")\n",
    "    \n",
    "    st = np.random.randint(0,2)\n",
    "    #st = round(st,0)\n",
    "    #hp.save(\"bbh_template_4k/bbh_4k_\"+str(i+1)+\".txt\")\n",
    "    #frame.write_frame(\"bbh_template_4k/bbh_4k_\"+str(i+1)+\".gwf\", , hp)\n",
    "    #pylab.plot(hp.sample_times, hp, label='H1')\n",
    "    #pylab.plot(noise)\n",
    "    signal = TimeSeries.from_pycbc(hp)\n",
    "    \n",
    "    # signal.write(\"new_data_4s_reduced_noise_no_abs/bns_signal/bns_signal_4s_bns_4k_\"+str(i)+\".txt\")\n",
    "    #noise.write(\"4s_new_generated_data/4s_noise_template_4k/4s_noise_4k_\"+str(i+1)+\".txt\")\n",
    "    #print(st)\n",
    "    \n",
    "    signal.t0 = st\n",
    "    data = noise.inject(signal)\n",
    "    #pylab.plot(data)\n",
    "    data.write(\"new_data_4s_reduced_noise_no_abs/merged_bns_noise_signal/bns_merged_noise_signal_\"+str(i)+\".txt\")\n",
    "\n",
    "#pylab.ylabel('Strain')\n",
    "#pylab.xlabel('Time (s)')\n",
    "#pylab.legend()\n",
    "#pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88ec32534dd4d0e8348da9da0944118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MERGING NOISE + SIgnal Templates into single file\n",
    "\n",
    "\n",
    "#for i in tqdm(range(5)):\n",
    "path = \"new_data_4s_reduced_noise_no_abs/merged_bns_noise_signal/\"\n",
    "files= os.listdir(path)\n",
    "f = open('new_data_4s_reduced_noise_no_abs/Final_BNS_Merged_Noise_Signal_Reduced_No_ABS.csv', 'w')\n",
    "cw = csv.writer(f)\n",
    "\n",
    "for i in tqdm(files):\n",
    "    df = pd.read_csv(path+i,sep = ' ', header=None)\n",
    "    c = df[:][1]\n",
    "    cw.writerow(c)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################\n",
    "##################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_n = \"4s_new_generated_data/4s_noise_template_4k/\"\n",
    "\n",
    "\n",
    "path_s = \"4s_new_generated_data/4s_bns_template_4k/\"\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    s = TimeSeries.read(path_s+\"4s_bns_4k_\"+str(i+1)+\".txt\")\n",
    "    n = TimeSeries.read(path_n+\"4s_noise_4k_\"+str(i+1)+\".txt\")\n",
    "    st = np.random.randint(0,2)\n",
    "    s.t0 = st\n",
    "    data = n.inject(s)\n",
    "    pylab.plot(n)\n",
    "    pylab.plot(s)\n",
    "        \n",
    "    data.write(\"4s_new_generated_data/4s_merged_bns_noise_signal/4s_merged_noise_signal_\"+str(i+1)+\".txt\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hp_bns, hc_bns = get_td_waveform(approximant=\"IMRPhenomPv2_NRTidal\",\n",
    " #                        mass1=bns_two_mass_samples[3][0],\n",
    " #                        mass2=bns_two_mass_samples[3][1],\n",
    " #                        delta_t=1.0/4096,\n",
    " #                        f_lower=200)\n",
    "#s = TimeSeries.read(path_s+\"4s_bns_4k_\"+str(1)+\".txt\")\n",
    "n = TimeSeries.read(path_n+\"4s_noise_4k_\"+str(1)+\".txt\")\n",
    "#pylab.plot(hp_bns.sample_times, hp_bns)\n",
    "n= n*(1e-19)\n",
    "pylab.scatter(n, range(16384))\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_bns, hc_bns = get_td_waveform(approximant=\"IMRPhenomPv2_NRTidal\",\n",
    "                  mass1=2,\n",
    "                   mass2=1.5,\n",
    "                     delta_t=1.0/4096,\n",
    "                      f_lower=40)\n",
    "pylab.scatter(hp_bns.sample_times,hp_bns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = TimeSeries.from_pycbc(hp_bns)\n",
    "#pylab.plot(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = n.inject(s)\n",
    "pylab.plot(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.scatter(d,range(16384))\n",
    "#pylab.scatter(n*1e-18,range(16384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "files= \"4s_new_generated_data/5000_4s_merged_bbh_noise_signal_no_abs/\"\n",
    "#data = [] # pd.concat takes a list of dataframes as an agrument\n",
    "for i in range(5):\n",
    "    #x=[]\n",
    "    \n",
    "    #print(csv)\n",
    "    frame = pd.read_csv(files+\"5000_4s_merged_noise_signal_3501\"+str(i+1)+\".txt\",sep = ' ', header=None)\n",
    "    \n",
    "    #print(frame)\n",
    "    #file_name = os.path.basename(csv)\n",
    "    #print(file_name)\n",
    "    #data.append(frame[:][1])\n",
    "    x  = list(frame[:][1])\n",
    "    #print(x)\n",
    "    df['signal_noise_template_'+str(i+1)] = x\n",
    "#print(df)\n",
    "\n",
    "df1 = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in df.items() ]))\n",
    "print(df1)\n",
    "#df1_transposed = df1.T\n",
    "#print(df1_transposed)\n",
    "df1.to_csv(\"4s_new_generated_data/sample_signal_noise.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "files= \"4s_new_generated_data/5000_4s_noise_template_4k_no_abs/\"\n",
    "#data = [] # pd.concat takes a list of dataframes as an agrument\n",
    "for i in range(5):\n",
    "    #x=[]\n",
    "    \n",
    "    #print(csv)\n",
    "    frame = pd.read_csv(files+\"5000_4s_noise_4k_350\"+str(i+1)+\".txt\",sep = ' ', header=None)\n",
    "    \n",
    "    #print(frame)\n",
    "    #file_name = os.path.basename(csv)\n",
    "    #print(file_name)\n",
    "    #data.append(frame[:][1])\n",
    "    x  = list(frame[:][1])\n",
    "    #print(x)\n",
    "    df['pure_noise_template_'+str(i+1)] = x\n",
    "#print(df)\n",
    "\n",
    "df1 = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in df.items() ]))\n",
    "print(df1)\n",
    "#df1= df1*1e-17\n",
    "print(df1)\n",
    "#df1_transposed = df1.T\n",
    "#print(df1_transposed)\n",
    "df1.to_csv(\"4s_new_generated_data/sample_pure_noise.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "files= \"4s_new_generated_data/5000_4s_bbh_template_4k_no_abs/\"\n",
    "#data = [] # pd.concat takes a list of dataframes as an agrument\n",
    "for i in range(5):\n",
    "    #x=[]\n",
    "    \n",
    "    #print(csv)\n",
    "    frame = pd.read_csv(files+\"5000_4s_bbh_4k_350\"+str(i+1)+\".txt\",sep = ' ', header=None)\n",
    "    \n",
    "    #print(frame)\n",
    "    #file_name = os.path.basename(csv)\n",
    "    #print(file_name)\n",
    "    #data.append(frame[:][1])\n",
    "    x  = list(frame[:][1])\n",
    "    #print(x)\n",
    "    df['only_signal_template_'+str(i+1)] = x\n",
    "#print(df)\n",
    "\n",
    "df1 = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in df.items() ]))\n",
    "print(df1)\n",
    "\n",
    "#df1_transposed = df1.T\n",
    "#print(df1_transposed)\n",
    "df1.to_csv(\"4s_new_generated_data/sample_signal.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"4s_new_generated_data/sample_pure_noise.csv\", header=None)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df)\n",
    "df = df.iloc[0: , :]\n",
    "print(df[0])\n",
    "\n",
    "plt.plot(df[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"4s_new_generated_data/5000_4s_bbh_template_4k_no_abs/5000_4s_bbh_4k_3501.txt\",sep=' ', header=None)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
