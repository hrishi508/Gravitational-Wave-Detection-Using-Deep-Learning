{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Dropout, MaxPool1D, ReLU, Flatten\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_class = 5000\n",
    "no_of_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_df = pd.read_csv(\"~/SOP/Gravitational Wave Detection Using Deep Learning/data/Final_Merged_Noise_Reduced_No_Abs.csv\", header=None)\n",
    "noise_X = noise_df.values.astype(float)\n",
    "# noise_y = np.zeros((samples_per_class , 1)).astype(float)\n",
    "\n",
    "\n",
    "data_df = pd.read_csv(\"~/SOP/Gravitational Wave Detection Using Deep Learning/data/Final_BBH_Merged_Noise_Signal_Reduced_No_ABS.csv\", header=None)\n",
    "data_X = data_df.values.astype(float)\n",
    "# data_y = np.ones((samples_per_class , 1)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "[[ 1.55952588e-19  9.48930874e-20 -2.03908807e-19 ... -1.42081173e-19\n",
      "   1.56639750e-19  2.06323581e-19]\n",
      " [ 1.68342261e-19 -2.32436731e-20  2.01099010e-19 ...  4.92764727e-20\n",
      "   6.88449772e-21  7.69596876e-20]\n",
      " [-1.77127428e-21 -1.16860154e-19 -2.75680221e-20 ...  9.51481870e-20\n",
      "   1.40486501e-19  1.42635313e-19]\n",
      " ...\n",
      " [ 1.24066490e-19  2.02760022e-19  7.02894628e-20 ... -1.74086976e-21\n",
      "   7.28379795e-20  6.74019667e-20]\n",
      " [-2.50812218e-19 -3.65408728e-19 -2.59820380e-19 ... -1.21963367e-19\n",
      "   4.15912167e-20 -2.15545938e-19]\n",
      " [-1.66340990e-19 -2.05033650e-20 -2.51719522e-19 ... -1.02534509e-19\n",
      "   1.37499247e-19 -3.59096226e-20]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((noise_X, data_X), axis=0)\n",
    "# Y = np.concatenate((noise_y, data_y), axis=0)\n",
    "\n",
    "print(len(noise_df.index))\n",
    "print(X)\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "# (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# print(y_train)\n",
    "# y_train = tf.keras.utils.to_categorical(y_train)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# print(y_train)\n",
    "# print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Alternate way of creating y for the dataset\n",
    " \n",
    "y = [int(i/samples_per_class) for i in range(samples_per_class*no_of_classes)]\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "\n",
    "# x = [[0,0],[1,1]]\n",
    "# a = [[0],[1]]\n",
    "# x = np.hstack((x, a))\n",
    "# # x\n",
    "# x, a, _ = np.split(x, [len(x[0])-1, len(x[0])], axis = 1)\n",
    "# x, a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.05570352e-20 -1.76292189e-19 -2.78905620e-19 ...  4.96658190e-20\n",
      "  -1.37709316e-19  2.02123267e-20]\n",
      " [ 1.67836074e-19  1.01601424e-19 -1.15978384e-20 ...  4.92470310e-20\n",
      "   4.50740090e-20 -1.09826435e-19]\n",
      " [ 3.70501874e-20  3.29739776e-20  4.96176489e-20 ...  1.14183882e-20\n",
      "  -1.08185780e-19 -1.65597939e-19]\n",
      " ...\n",
      " [-1.81626457e-20  1.40824971e-20  1.49160302e-19 ... -1.48777901e-19\n",
      "  -1.08221047e-19  2.71519506e-20]\n",
      " [-2.68313188e-19 -9.82505725e-20 -3.11455516e-19 ...  3.27260202e-20\n",
      "   5.94208046e-20 -1.45863531e-19]\n",
      " [-5.73372557e-20 -4.05587457e-20 -1.05371917e-19 ... -1.13198792e-19\n",
      "   7.55365287e-20 -2.39195113e-20]]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# shuffling the data\n",
    "\n",
    "X = np.hstack((X, y))\n",
    "np.random.shuffle(X)\n",
    "\n",
    "X, y, _ = np.split(X, [len(X[0])-no_of_classes, len(X[0])], axis = 1)\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.66502223e-01 -1.07359821e+00 -1.74433671e+00 ...  5.02581170e-01\n",
      "  -1.36933782e+00  2.26637884e-01]\n",
      " [ 1.12471825e+00  7.27310905e-01 -1.06618344e-03 ...  4.98396855e-01\n",
      "   4.52394582e-01 -1.06678426e+00]\n",
      " [ 2.86896372e-01  2.82565906e-01  3.98155846e-01 ...  1.20432591e-01\n",
      "  -1.07508789e+00 -1.62151193e+00]\n",
      " ...\n",
      " [-6.68001951e-02  1.60138337e-01  1.04733176e+00 ... -1.48016600e+00\n",
      "  -1.07543938e+00  2.95662405e-01]\n",
      " [-1.66927888e+00 -5.67844024e-01 -1.95661364e+00 ...  3.33327448e-01\n",
      "   5.95383678e-01 -1.42522492e+00]\n",
      " [-3.17754987e-01 -1.93968081e-01 -6.12621844e-01 ... -1.12467792e+00\n",
      "   7.56003017e-01 -2.12316594e-01]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "\n",
    "# x = [[0,0],[1,1]]\n",
    "# y = np.expand_dims(x, axis=-1)\n",
    "# print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 32, input_shape = (16384,1)))\n",
    "model.add(MaxPool1D(4, 4))\n",
    "model.add(ReLU())\n",
    "model.add(Conv1D(128, 64))\n",
    "model.add(MaxPool1D(4, 4))\n",
    "model.add(ReLU())\n",
    "model.add(Conv1D(256, 64))\n",
    "model.add(MaxPool1D(4, 4))\n",
    "model.add(ReLU())\n",
    "model.add(Conv1D(512, 128))\n",
    "model.add(MaxPool1D(4, 4))\n",
    "model.add(ReLU())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(13824))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))                         # dropout rate not givem\n",
    "model.add(Dense(2, activation=tf.nn.softmax))\n",
    "\n",
    "# learning rate not given\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 16353, 64)         2112      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 4088, 64)          0         \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 4088, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 4025, 128)         524416    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1006, 128)         0         \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 1006, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 943, 256)          2097408   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 235, 256)          0         \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 235, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 108, 512)          16777728  \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 27, 512)           0         \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 27, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 13824)             191116800 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1769600   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 212,296,450\n",
      "Trainable params: 212,296,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16384, 1) (10000, 2)\n",
      "(1600, 16384, 1) (1600, 2)\n",
      "(400, 16384, 1) (400, 2)\n"
     ]
    }
   ],
   "source": [
    "# print(X1.shape, y.shape)\n",
    "# X2 = X1[:1600, :]\n",
    "# y2 = y[:1600, :]\n",
    "\n",
    "# X3 = X1[1600:2000, :]\n",
    "# y3 = y[1600:2000, :]\n",
    "# print(X2.shape, y2.shape)\n",
    "print(X3.shape, y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16384) (10000, 2)\n",
      "(10, 16384, 1) (10, 2)\n",
      "(2, 16384, 1) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# print(X.shape, y.shape)\n",
    "# X2 = X[:10, :]\n",
    "# y2 = y[:10, :]\n",
    "\n",
    "# X3 = X[10:12, :]\n",
    "# y3 = y[10:12, :]\n",
    "\n",
    "# X2 = np.expand_dims(X2, axis=-1)\n",
    "# X3 = np.expand_dims(X3, axis=-1)\n",
    "# print(X2.shape, y2.shape)\n",
    "# print(X3.shape, y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 65s 22s/step - loss: 0.6341 - accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 10.4500 - accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.5176 - accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.1255 - accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6633 - accuracy: 0.7000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6787 - accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6364 - accuracy: 0.7000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6168 - accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6582 - accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6132 - accuracy: 0.7000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.5807 - accuracy: 0.7000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6353 - accuracy: 0.7000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6313 - accuracy: 0.7000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6148 - accuracy: 0.7000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6381 - accuracy: 0.7000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6317 - accuracy: 0.7000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6224 - accuracy: 0.7000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6902 - accuracy: 0.7000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6365 - accuracy: 0.7000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6492 - accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb513fb2dd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=10) #, validation_data=(X3, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8356d31dd4c50017c60d528a0c40a4935f9d791f54e24c10e32e3a312d5b6882"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
