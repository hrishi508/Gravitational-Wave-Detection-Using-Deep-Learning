# Model Architecture :
The following model has been obtained from the paper authored by Ismail Fawaz [1]. You can read this paper [here](/Literature%20Review/Classification/RESNET/1809.04356.pdf).
``` 
Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 16384, 1)]   0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 16384, 64)    576         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 16384, 64)    256         conv1d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 16384, 64)    0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 16384, 64)    20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 16384, 64)    256         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 16384, 64)    0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 16384, 64)    128         input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 16384, 64)    12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16384, 64)    256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 16384, 64)    256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 16384, 64)    0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 16384, 64)    0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 16384, 128)   65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 16384, 128)   512         conv1d_4[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 16384, 128)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 16384, 128)   82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 16384, 128)   512         conv1d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 16384, 128)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 16384, 128)   8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 16384, 128)   49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 16384, 128)   512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 16384, 128)   512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 16384, 128)   0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 16384, 128)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 16384, 128)   131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16384, 128)   512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 16384, 128)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 16384, 128)   82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16384, 128)   512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 16384, 128)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 16384, 128)   49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16384, 128)   512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16384, 128)   512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 16384, 128)   0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16384, 128)   0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 506,818
Trainable params: 504,258
Non-trainable params: 2,560
__________________________________________________________________________________________________
```

# Classes :
```
1. Noise 
2. BBH signal + Noise
```

# Dataset :
To generate this dataset, use the "IMPORTS" section (code cell no. 1) and the "BBH Data Generation" section (code cell no. 2-6) of the [Data Generation](/scripts/Data%20Generation.ipynb) script.
```
| S.No. | Data Type          | Mode of generation   | No. of Samples |
| ----- | ------------------ | -------------------- | -------------- |
| 1     | Noise              | Gaussian             | 5000           |
| ----- | ------------------ | -------------------- | -------------- |
| 2     | BBH signal + Noise | SEOBNRv2             | 5000           |
| ----- | ------------------ | -------------------- | -------------- |
```

# Comments:
1. Though the no. of parameters in this model is lesser than Krastev, it takes a lot of time for training. About 10 mins per epoch.
2. If we try to increase the batch size from 32 to 64, the colab session crashes due to insufficient RAM, thus, we are forced to use a batch size of 32 which  slows down the training process even further.

# References :
1. Fawaz, H.I., Forestier, G., Weber, J., Idoumghar, L. and Muller, P.A., (2018). Deep learning for time series classification: a review. arXiv preprint arXiv: 180904356.

