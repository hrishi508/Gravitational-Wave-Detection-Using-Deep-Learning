{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs_OpQDIxDQW",
        "outputId": "2ca8f5f6-fb86-41e6-9ffb-1d5fcff449d6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5inbyEdw1A7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Dropout, MaxPool1D, ReLU, Flatten\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF5cR2kzw1A-"
      },
      "outputs": [],
      "source": [
        "samples_per_class = 5000\n",
        "no_of_classes = 2\n",
        "directory = \"/content/gdrive/MyDrive/GW_SOP/Code/debugging/1D-CNN Binary Classification/Signal_HIDDEN_in_strain_data/Signal_WHITENED/Test 5/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzCUizYfw1A_"
      },
      "outputs": [],
      "source": [
        "noise_df = pd.read_csv(directory + \"Final_Merged_Noise_Reduced_No_Abs.csv\", header=None)\n",
        "noise = noise_df.values.astype(float)\n",
        "\n",
        "\n",
        "data_BBH_df = pd.read_csv(directory + \"Final_BBH_Merged_Noise_Signal.csv\", header=None)\n",
        "data_BBH = data_BBH_df.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmYHuecJw1BB",
        "outputId": "e9ddbf4b-0eea-4203-be3a-5ed497f6235f"
      },
      "outputs": [],
      "source": [
        "X = np.concatenate((noise, data_BBH), axis=0)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_dSmj6xw1BE",
        "outputId": "99a34d7a-396f-40ac-8ca6-125cb9c6d93a"
      },
      "outputs": [],
      "source": [
        "y = [int(i/samples_per_class) for i in range(samples_per_class*no_of_classes)]\n",
        "y = tf.keras.utils.to_categorical(y)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9h1LUqxBQgm",
        "outputId": "f5e72b6d-1048-431d-8142-4b89c90f5866"
      },
      "outputs": [],
      "source": [
        "X *= 1e18\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xirD0GDBQgm",
        "outputId": "1e439b6f-a531-438d-ed21-196641060ff7"
      },
      "outputs": [],
      "source": [
        "X = np.expand_dims(X, axis=-1)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01pIkFC6w1BJ"
      },
      "outputs": [],
      "source": [
        "def create_model():    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv1D(16, 16, input_shape = (16384,1)))\n",
        "    model.add(MaxPool1D(4, 4))\n",
        "    model.add(ReLU())\n",
        "    model.add(Conv1D(32, 8))\n",
        "    model.add(MaxPool1D(4, 4))\n",
        "    model.add(ReLU())\n",
        "    model.add(Conv1D(64, 8))\n",
        "    model.add(MaxPool1D(4, 4))\n",
        "    model.add(ReLU())\n",
        "    model.add(Conv1D(128, 8))\n",
        "    model.add(MaxPool1D(4, 4))\n",
        "    model.add(ReLU())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itdIDW8hat5I",
        "outputId": "bdd49d31-5cd6-4e71-b4d6-a5bcb6bcc648"
      },
      "outputs": [],
      "source": [
        "N_splits = 5\n",
        "n_epochs = 5\n",
        "\n",
        "kf = KFold(n_splits = N_splits, shuffle = True)\n",
        "acc = [0 for i in range(6)]\n",
        "loss = [0 for i in range(5)]\n",
        "precision = 0\n",
        "recall = 0\n",
        "score = 0\n",
        "cm = np.zeros((2,2))\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    \n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "    # print(y_train)\n",
        "    # print(y_test)\n",
        "\n",
        "    model = create_model()\n",
        "    history = model.fit(X_train, y_train, batch_size=128, epochs=n_epochs)\n",
        "\n",
        "    print(\"---------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "    tmp_acc = history.history['accuracy']\n",
        "    tmp_loss = history.history['loss']\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "        acc[i+1] += tmp_acc[i]\n",
        "        loss[i] += tmp_loss[i]\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(pred, axis = 1)\n",
        "    y_true = np.argmax(y_test, axis = 1)\n",
        "\n",
        "    precision += precision_score(y_true, y_pred, average='binary')\n",
        "    recall += recall_score(y_true, y_pred, average='binary')\n",
        "    score += f1_score(y_true, y_pred, average='binary')\n",
        "    cm = np.add(cm, confusion_matrix(y_true, y_pred, labels=[0, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlsTBrdIat5K",
        "outputId": "aff85734-b4b8-4c37-aff2-204070c58a3a"
      },
      "outputs": [],
      "source": [
        "final_accuracy = acc[n_epochs]/N_splits\n",
        "final_precision = precision/N_splits\n",
        "final_recall = recall/N_splits\n",
        "final_score = score/N_splits\n",
        "final_cm = cm/N_splits\n",
        "\n",
        "print('Accuracy: %.3f' % final_accuracy)\n",
        "print('Precision: %.3f' % final_precision)\n",
        "print('Recall: %.3f' % final_recall)\n",
        "print('F1-Score: %.3f' % final_score)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=final_cm, display_labels=[0, 1])\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqssaFdDw1BN",
        "outputId": "99dd605d-4b48-41e9-943c-e7165d727add"
      },
      "outputs": [],
      "source": [
        "acc_1 = [acc[i]/N_splits for i in range(n_epochs+1)]\n",
        "loss_1 = [loss[i]/N_splits for i in range(n_epochs)]\n",
        "\n",
        "plt.figure(figsize=(13, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc_1, label='Training Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss_1, label='Training Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Categorical Cross Entropy')\n",
        "plt.ylim([0,2])\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "test_5_5_fold_validation.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8356d31dd4c50017c60d528a0c40a4935f9d791f54e24c10e32e3a312d5b6882"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
