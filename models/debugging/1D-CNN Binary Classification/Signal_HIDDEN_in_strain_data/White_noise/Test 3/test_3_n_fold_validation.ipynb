{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs_OpQDIxDQW",
        "outputId": "1cbdf355-bdd3-43b8-fb3b-a76c8e30e1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L5inbyEdw1A7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Dropout, MaxPool1D, ReLU, Flatten\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hF5cR2kzw1A-"
      },
      "outputs": [],
      "source": [
        "samples_per_class = 5000\n",
        "no_of_classes = 2\n",
        "directory = \"/content/gdrive/MyDrive/GW_SOP/Code/debugging/1D-CNN Binary Classification/Signal_HIDDEN_in_strain_data/White_noise/Test 3/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MzCUizYfw1A_"
      },
      "outputs": [],
      "source": [
        "noise_df = pd.read_csv(directory + \"Final_Merged_Noise_Reduced_No_Abs.csv\", header=None)\n",
        "noise = noise_df.values.astype(float)\n",
        "noise = np.repeat(noise, 5000, 0)\n",
        "\n",
        "\n",
        "data_BBH_df = pd.read_csv(directory + \"Final_BBH_Merged_Noise_Signal.csv\", header=None)\n",
        "data_BBH = data_BBH_df.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_df = None\n",
        "data_BBH_df = None"
      ],
      "metadata": {
        "id": "GDc6pCgFyeVg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmYHuecJw1BB",
        "outputId": "ed2d440b-fc7c-4f22-8985-4be36c36205a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 16384)\n"
          ]
        }
      ],
      "source": [
        "X = np.concatenate((noise, data_BBH), axis=0)\n",
        "X = X[:10000, :]\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_dSmj6xw1BE",
        "outputId": "b02f634e-11c5-4f92-b1f7-407d810a0fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 2)\n"
          ]
        }
      ],
      "source": [
        "y = [int(i/samples_per_class) for i in range(samples_per_class*no_of_classes)]\n",
        "y = tf.keras.utils.to_categorical(y)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9h1LUqxBQgm",
        "outputId": "6ced8405-7529-4e3f-a91b-4d1769be8256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  8.93065247  35.24599602  -3.12360718 ...  -5.10161839 -13.58640057\n",
            "    9.90881031]\n",
            " [  8.93065247  35.24599602  -3.12360718 ...  -5.10161839 -13.58640057\n",
            "    9.90881031]\n",
            " [  8.93065247  35.24599602  -3.12360718 ...  -5.10161839 -13.58640057\n",
            "    9.90881031]\n",
            " ...\n",
            " [ 23.67764714   4.9866287   -9.84717529 ...  32.92576831  -1.30098777\n",
            "  -13.52575058]\n",
            " [ 23.67764714   4.9866287   -9.84717529 ...  32.92576831  -1.30098777\n",
            "  -13.52575058]\n",
            " [ 23.67764714   4.9866287   -9.84717529 ...  32.92576831  -1.30098777\n",
            "  -13.52575058]]\n"
          ]
        }
      ],
      "source": [
        "X *= 1e19\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xirD0GDBQgm",
        "outputId": "0c90ff22-03b7-4c03-c9cc-564303924bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 16384, 1)\n"
          ]
        }
      ],
      "source": [
        "X = np.expand_dims(X, axis=-1)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "01pIkFC6w1BJ"
      },
      "outputs": [],
      "source": [
        "def create_model():    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv1D(16, 16, input_shape = (16384,1)))\n",
        "    model.add(MaxPool1D(4, 4))\n",
        "    model.add(ReLU())\n",
        "    model.add(Conv1D(32, 8))\n",
        "    model.add(MaxPool1D(4, 4))\n",
        "    model.add(ReLU())\n",
        "    model.add(Conv1D(64, 8))\n",
        "    model.add(MaxPool1D(4, 4))\n",
        "    model.add(ReLU())\n",
        "    model.add(Conv1D(128, 8))\n",
        "    model.add(MaxPool1D(4, 4))\n",
        "    model.add(ReLU())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itdIDW8hat5I",
        "outputId": "970c7de0-84d5-411d-dcab-35675e301334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "63/63 [==============================] - 4s 46ms/step - loss: 0.3164 - accuracy: 0.9534\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.6418e-05 - accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 8.5557e-06 - accuracy: 1.0000\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.1958 - accuracy: 0.9750\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 4.1135e-06 - accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.3214e-06 - accuracy: 1.0000\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.1787 - accuracy: 0.9660\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 4.9655e-06 - accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.6743e-06 - accuracy: 1.0000\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/3\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 0.1226 - accuracy: 0.9675\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 8.7176e-07 - accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 4.3736e-07 - accuracy: 1.0000\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "Epoch 1/3\n",
            "25/63 [==========>...................] - ETA: 1s - loss: 0.7121 - accuracy: 0.8516"
          ]
        }
      ],
      "source": [
        "N_splits = 5\n",
        "n_epochs = 3\n",
        "\n",
        "kf = KFold(n_splits = N_splits, shuffle = True)\n",
        "acc = [0 for i in range(n_epochs+1)]\n",
        "loss = [0 for i in range(n_epochs)]\n",
        "precision = 0\n",
        "recall = 0\n",
        "score = 0\n",
        "cm = np.zeros((2,2))\n",
        "\n",
        "precision_train = 0\n",
        "recall_train = 0\n",
        "score_train = 0\n",
        "cm_train = np.zeros((2,2))\n",
        "k = 1\n",
        "\n",
        "final = plt.figure()\n",
        "plt.xlabel('False Positive Rate', figure = final)\n",
        "plt.ylabel('True Positive Rate', figure = final)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.xlabel('False Positive Rate', figure = fig)\n",
        "    plt.ylabel('True Positive Rate', figure = fig)\n",
        "    \n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "    # print(y_train)\n",
        "    # print(y_test)\n",
        "\n",
        "    model = create_model()\n",
        "    history = model.fit(X_train, y_train, batch_size=128, epochs=n_epochs)\n",
        "\n",
        "    print(\"---------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "    tmp_acc = history.history['accuracy']\n",
        "    tmp_loss = history.history['loss']\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "        acc[i+1] += tmp_acc[i]\n",
        "        loss[i] += tmp_loss[i]\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(pred, axis = 1)\n",
        "    y_true = np.argmax(y_test, axis = 1)\n",
        "\n",
        "    pred_train = model.predict(X_train)\n",
        "    y_pred_train = np.argmax(pred_train, axis = 1)\n",
        "    y_true_train = np.argmax(y_train, axis = 1)\n",
        "\n",
        "    precision += precision_score(y_true, y_pred, average='binary')\n",
        "    recall += recall_score(y_true, y_pred, average='binary')\n",
        "    score += f1_score(y_true, y_pred, average='binary')\n",
        "    cm = np.add(cm, confusion_matrix(y_true, y_pred, labels=[0, 1]))\n",
        "\n",
        "    precision_train += precision_score(y_true_train, y_pred_train, average='binary')\n",
        "    recall_train += recall_score(y_true_train, y_pred_train, average='binary')\n",
        "    score_train += f1_score(y_true_train, y_pred_train, average='binary')\n",
        "    cm_train = np.add(cm_train, confusion_matrix(y_true_train, y_pred_train, labels=[0, 1]))\n",
        "\n",
        "    pos_probs = pred[:,1]\n",
        "    fpr, tpr, _ = roc_curve(y_true, pos_probs)\n",
        "    plt.plot(fpr, tpr, figure = fig, label = 'Fold No. ' + str(k))\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.savefig(directory + 'roc_'+str(N_splits)+'-fold_'+str(k)+'.png', figure = fig)\n",
        "    plt.close()\n",
        "    plt.plot(fpr, tpr, figure = final, label = 'Fold No. ' + str(k))\n",
        "    k += 1\n",
        "\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "\n",
        "final_accuracy = acc[n_epochs]/N_splits\n",
        "final_precision = precision_train/N_splits\n",
        "final_recall = recall_train/N_splits\n",
        "final_score = score_train/N_splits\n",
        "final_cm = cm_train/N_splits\n",
        "\n",
        "print('Accuracy: %.3f' % final_accuracy)\n",
        "print('Precision: %.3f' % final_precision)\n",
        "print('Recall: %.3f' % final_recall)\n",
        "print('F1-Score: %.3f' % final_score)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=final_cm, display_labels=[0, 1])\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Ibt5Fqfo-NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlsTBrdIat5K"
      },
      "outputs": [],
      "source": [
        "# Test Data\n",
        "\n",
        "final_precision = precision/N_splits\n",
        "final_recall = recall/N_splits\n",
        "final_score = score/N_splits\n",
        "final_cm = cm/N_splits\n",
        "\n",
        "print('Precision: %.3f' % final_precision)\n",
        "print('Recall: %.3f' % final_recall)\n",
        "print('F1-Score: %.3f' % final_score)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=final_cm, display_labels=[0, 1])\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqssaFdDw1BN"
      },
      "outputs": [],
      "source": [
        "acc_1 = [acc[i]/N_splits for i in range(n_epochs+1)]\n",
        "loss_1 = [loss[i]/N_splits for i in range(n_epochs)]\n",
        "\n",
        "plt.figure(figsize=(13, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc_1, label='Training Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss_1, label='Training Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Categorical Cross Entropy')\n",
        "plt.ylim([0,2])\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "test_3_n_fold_validation.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8356d31dd4c50017c60d528a0c40a4935f9d791f54e24c10e32e3a312d5b6882"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}