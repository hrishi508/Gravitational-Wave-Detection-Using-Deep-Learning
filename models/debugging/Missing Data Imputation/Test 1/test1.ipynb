{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/home/hrishi/SOP/Gravitational Wave Detection Using Deep Learning/models/debugging/Missing Data Imputation/Test 1/data/\"\n",
    "MASK_FILE = BASE_PATH + \"mask.csv\"\n",
    "DATA_FILE = BASE_PATH + \"data.csv\"\n",
    "WEIGHTS_PATH = BASE_PATH + \"weights.pth\"\n",
    "NOISE_DURATION = 600 # in sec\n",
    "SAMPLING_FREQUENCY = 4096\n",
    "TOTAL_SAMPLES = 1000\n",
    "NO_OF_TRAINING_SAMPLES = 1000\n",
    "NO_OF_TESTING_SAMPLES = 1000\n",
    "\n",
    "# Hyperparameters\n",
    "INPUT_SIZE = 1\n",
    "HIDDEN_SIZE = 50\n",
    "DEVICE = \"cuda\"\n",
    "LR = 1e-3\n",
    "LOAD_WEIGHTS = False\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imputationLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstmcell = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, input_size)\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        hx = torch.randn(x.size()[1], self.hidden_size)\n",
    "        cx = torch.randn(x.size()[1], self.hidden_size)\n",
    "        next_input = torch.randn(x.size()[1], self.input_size)\n",
    "        output = [[] for i in range(x.size()[1])]\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(-1, x.size()[0]):\n",
    "            if i == -1:\n",
    "                hx, cx = self.lstmcell(next_input, (hx, cx))\n",
    "\n",
    "            else:\n",
    "                hx, cx = self.lstmcell(next_input, (hx, cx))\n",
    "\n",
    "            if i != x.size()[0]-1:\n",
    "                tmp_mask = torch.tensor(mask[:, i+1], dtype=bool)\n",
    "                inv_tmp_mask = torch.tensor(~mask[:, i+1], dtype=bool)\n",
    "                tmp_out = self.linear(hx)\n",
    "\n",
    "                next_input = torch.mul(tmp_out, tmp_mask) + torch.mul(x[i+1], inv_tmp_mask) \n",
    "                loss += self.mse_loss(next_input, x[i+1])\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for j in range(len(mask[:, i+1])):\n",
    "                        if mask[j, i+1]:\n",
    "                            output[j].append(tmp_out[j, 0])\n",
    "        \n",
    "        output = torch.stack(output, dim=0)\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.read_csv(MASK_FILE, header=None)\n",
    "start_time = np.array(start_time.values.astype(float).flatten())\n",
    "\n",
    "MISSING_DURATION = start_time[0]\n",
    "start_time = start_time[1:].astype(int)\n",
    "\n",
    "MISSING_LENGTH = int(MISSING_DURATION*SAMPLING_FREQUENCY)\n",
    "MASK_SIZE = int(NOISE_DURATION*SAMPLING_FREQUENCY)\n",
    "\n",
    "data = pd.read_csv(DATA_FILE, header=None)\n",
    "data = data.values.astype(float)\n",
    "\n",
    "X = np.repeat(data, 64, 0)\n",
    "X = np.expand_dims(X, -1)\n",
    "X = np.swapaxes(X, 0, 1)\n",
    "\n",
    "model = imputationLSTM(INPUT_SIZE, HIDDEN_SIZE).to(DEVICE)\n",
    "# summary(model, (3, 112, 112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertStartTimeToMask(start_time, missing_length, mask_size=600*4096):\n",
    "    mask = np.zeros((start_time.shape[0], mask_size))\n",
    "\n",
    "    for i in range(start_time.shape[0]):\n",
    "        mask[i, start_time[i]:start_time[i]+missing_length] = 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "def train(X, start_time, model, train_loss_arr, optimizer, batch_size=64):\n",
    "    size = NO_OF_TRAINING_SAMPLES\n",
    "    num_batches = math.ceil(size/batch_size)\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    start_time = torch.tensor(X)\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        if i != num_batches-1:\n",
    "            time = start_time[i*batch_size : (i+1)*batch_size].to(DEVICE)\n",
    "\n",
    "        else:\n",
    "            time = start_time[i*batch_size :].to(DEVICE)\n",
    "\n",
    "        X.requires_grad = True\n",
    "        mask = convertStartTimeToMask(time, MISSING_LENGTH, MASK_SIZE)\n",
    "\n",
    "        out, loss = model(X, mask)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # For visualizing the model\n",
    "        # make_dot((out, loss), params=dict(list(model.named_parameters()))).render(\"imputationLSTM\", format=\"png\")        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    print(f\"\\nTraining - Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "    train_loss_arr.append(train_loss)\n",
    "\n",
    "def test(X, start_time, model, test_loss_arr, batch_size=64):\n",
    "    size = NO_OF_TRAINING_SAMPLES\n",
    "    num_batches = math.ceil(size/batch_size)\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    start_time = torch.tensor(X)\n",
    "    \n",
    "    model.train()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_batches):\n",
    "            if i != num_batches-1:\n",
    "                time = start_time[i*batch_size : (i+1)*batch_size].to(DEVICE)\n",
    "\n",
    "            else:\n",
    "                time = start_time[i*batch_size :].to(DEVICE)\n",
    "\n",
    "            X.requires_grad = True\n",
    "            mask = convertStartTimeToMask(time, MISSING_LENGTH, MASK_SIZE)\n",
    "\n",
    "            out, loss = model(X, mask)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Testing - Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    test_loss_arr.append(test_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_WEIGHTS:\n",
    "    model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR) # , weight_decay=cfg.weight_decay\n",
    "\n",
    "train_loss_arr = []\n",
    "test_loss_arr = []\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(X, start_time, model, train_loss_arr, optimizer)\n",
    "    # test(test_loader, model, loss_fn_arr, test_loss_arr)\n",
    "        \n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_%H:%M:%S_\")\n",
    "torch.save(model.state_dict(), BASE_PATH + dt_string + f\"weights.pth\")\n",
    "\n",
    "x = [i+1 for i in range(EPOCHS)]\n",
    "plt.plot(x, train_loss_arr, 'g', label='train')\n",
    "# plt.plot(x, test_loss_arr, 'r', label='test')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(BASE_PATH + dt_string + \"loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
