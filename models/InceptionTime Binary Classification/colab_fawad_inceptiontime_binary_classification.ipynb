{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs_OpQDIxDQW",
        "outputId": "2c318b83-3400-4513-e1df-ec167dad8688"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L5inbyEdw1A7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# RESNET IMPORTS\n",
        "import time\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('agg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hF5cR2kzw1A-"
      },
      "outputs": [],
      "source": [
        "samples_per_class = 5000\n",
        "no_of_classes = 2\n",
        "directory = \"/content/gdrive/MyDrive/GW_SOP/Data/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzCUizYfw1A_"
      },
      "outputs": [],
      "source": [
        "noise_df = pd.read_csv(directory + \"Final_Merged_Noise_Reduced_No_Abs.csv\", header=None)\n",
        "noise = noise_df.values.astype(float)\n",
        "\n",
        "\n",
        "data_BBH_df = pd.read_csv(directory + \"Final_BBH_Merged_Noise_Signal_Reduced_No_ABS.csv\", header=None)\n",
        "data_BBH = data_BBH_df.values.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmYHuecJw1BB",
        "outputId": "5f2379b5-a96f-454d-b6a5-16f54286afab"
      },
      "outputs": [],
      "source": [
        "X = np.concatenate((noise, data_BBH), axis=0)\n",
        "\n",
        "print(len(noise_df.index))\n",
        "print(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_dSmj6xw1BE",
        "outputId": "ebbe52aa-b078-4cca-f065-4a78a67a96dd"
      },
      "outputs": [],
      "source": [
        "# Alternate way of creating y for the dataset\n",
        " \n",
        "y = [int(i/samples_per_class) for i in range(samples_per_class*no_of_classes)]\n",
        "y = tf.keras.utils.to_categorical(y)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9h1LUqxBQgm"
      },
      "outputs": [],
      "source": [
        "X *= 1e19\n",
        "print(X)\n",
        "\n",
        "# X *= 1e18\n",
        "# print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xirD0GDBQgm",
        "outputId": "907999f7-ba46-4f93-88e5-c4e8b6fe8d26"
      },
      "outputs": [],
      "source": [
        "X = np.expand_dims(X, axis=-1)\n",
        "print(X.shape)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxu2uCZyz8kD"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cqz7kE80mty",
        "outputId": "09d19ddc-c0d4-4eee-9e0c-5ddfd96dca04"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "01pIkFC6w1BJ"
      },
      "outputs": [],
      "source": [
        "# resnet model\n",
        "class Classifier_INCEPTION:\n",
        "\n",
        "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, build=True, batch_size=64,\n",
        "                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=5):\n",
        "\n",
        "        self.output_directory = output_directory\n",
        "\n",
        "        self.nb_filters = nb_filters\n",
        "        self.use_residual = use_residual\n",
        "        self.use_bottleneck = use_bottleneck\n",
        "        self.depth = depth\n",
        "        self.kernel_size = kernel_size - 1\n",
        "        self.callbacks = None\n",
        "        self.batch_size = batch_size\n",
        "        self.bottleneck_size = 32\n",
        "        self.nb_epochs = nb_epochs\n",
        "\n",
        "        if build == True:\n",
        "            self.model = self.build_model(input_shape, nb_classes)\n",
        "            if (verbose == True):\n",
        "                self.model.summary()\n",
        "            self.verbose = verbose\n",
        "\n",
        "    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n",
        "\n",
        "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
        "            input_inception = keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n",
        "                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n",
        "        else:\n",
        "            input_inception = input_tensor\n",
        "\n",
        "        # kernel_size_s = [3, 5, 8, 11, 17]\n",
        "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
        "\n",
        "        conv_list = []\n",
        "\n",
        "        for i in range(len(kernel_size_s)):\n",
        "            conv_list.append(keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n",
        "                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n",
        "                input_inception))\n",
        "\n",
        "        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
        "\n",
        "        conv_6 = keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n",
        "                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
        "\n",
        "        conv_list.append(conv_6)\n",
        "\n",
        "        x = keras.layers.Concatenate(axis=2)(conv_list)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.Activation(activation='relu')(x)\n",
        "        return x\n",
        "\n",
        "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
        "        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
        "                                         padding='same', use_bias=False)(input_tensor)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "        x = keras.layers.Add()([shortcut_y, out_tensor])\n",
        "        x = keras.layers.Activation('relu')(x)\n",
        "        return x\n",
        "\n",
        "    def build_model(self, input_shape, nb_classes):\n",
        "        input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "        x = input_layer\n",
        "        input_res = input_layer\n",
        "\n",
        "        for d in range(self.depth):\n",
        "\n",
        "            x = self._inception_module(x)\n",
        "\n",
        "            if self.use_residual and d % 3 == 2:\n",
        "                x = self._shortcut_layer(input_res, x)\n",
        "                input_res = x\n",
        "\n",
        "        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
        "\n",
        "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50,\n",
        "                                                      min_lr=0.0001)\n",
        "\n",
        "        self.callbacks = [reduce_lr]\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, x_train, y_train, x_val, y_val):\n",
        "        # x_val and y_val are only used to monitor the test loss and NOT for training\n",
        "\n",
        "        hist = self.model.fit(x_train, y_train, batch_size=self.batch_size, epochs=self.nb_epochs, validation_data=(x_val, y_val), callbacks=self.callbacks)\n",
        "\n",
        "        keras.backend.clear_session()\n",
        "\n",
        "        return hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2PqOqLjw1BK"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "\n",
        "InceptionTime = Classifier_INCEPTION(directory, (16384, 1), 2, verbose = False, batch_size = BATCH_SIZE, nb_epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxVd6XC9w1BM",
        "outputId": "35808604-3485-4b15-e671-019cec865d9f"
      },
      "outputs": [],
      "source": [
        "history = InceptionTime.fit(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IqssaFdDw1BN",
        "outputId": "b80a4862-271a-47ab-ba19-4e8b895c1097"
      },
      "outputs": [],
      "source": [
        "acc = [0.] + history.history['accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "\n",
        "plt.figure(figsize=(13, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Categorical Cross Entropy')\n",
        "plt.ylim([0,2])\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = InceptionTime.model.predict(X)\n",
        "y_pred = np.argmax(pred, axis = 1)\n",
        "y_true = np.argmax(y, axis = 1)\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='binary')\n",
        "print('Precision: %.3f' % precision)\n",
        "\n",
        "recall = recall_score(y_true, y_pred, average='binary')\n",
        "print('Recall: %.3f' % recall)\n",
        "\n",
        "score = f1_score(y_true, y_pred, average='binary')\n",
        "print('F1-Score: %.3f' % score)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "colab_krastev_1dcnn_multi_classification.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8356d31dd4c50017c60d528a0c40a4935f9d791f54e24c10e32e3a312d5b6882"
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
